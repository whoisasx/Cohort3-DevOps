* go through the notes of previous class before attending the next one.

# week 24.1
1. create a digital ocean account.
    - using ssh key for verification.
    - generate the ssh key on the local machine inside the .ssh folder and using 
      the command 'ssh-keygen'.
2. serve a demo webpage over there.
3. access it by the public domain.

#week 24.2
1.get a GCP account and initiate a virutal machine. 
2.replace nginx with traefic/HAproxy/apache.
3.try deploying a react project.
4.get a domain (namecheap). DONE
5.try ASGs
6.try to do certificate managaement yourself.
7.create a ci/cd pipeline to auto deploy your server from github.
8.forever or pm2(process management)

------------------------------------------------------------------------------------------------

#week 25.2
1. create a monorepo with apps (ws, http, web) and each of them to database and push it to github.
2.  - create 2 servers.
    - add node, nginx to both the servers and also the pnpm.
    - clone the monorepo to both the servers.
    - start all three process http,ws and web.
    - point the name to the specific servers.
    - also deploy the staging websites. 
    - refresh ngnix config.
    - test everything is working.
3. create a ci/cd pipeline.

    {
        whenever we open a terminal anywhere, it automatically source the shell files like (.bashrc,zshrc etc.) but only in the interactive shell. so if we manually ssh into the virtual machine(vm) the shell is interactive and hence the shell files are sourced and we get desired access to the nvm , node , npm and all if they are already installed.
        but in case of github, when github server ssh into the vm , its shell is non-interactive and hence no shell files are sourced and hence no access to anything like node,nvm or npm.
        it will display:[Pseudo-terminal will not be allocated because stdin is not a terminal.]

        even though you manually include the command to source nvm in the deployment file, it still misses the path where all the commands are stored of node and all.
    }

----------------------------------------------------------------------------------------------

#week 26.1
1. install docker Desktop and sign up.
    - run mongo image locally and also remove it.
2. docker image v/s container.
    - image: standalone package contains or encapsulate everything required to run a piece of software. [analogy: consider it as a class.]
    - container: an instance of an image and may be created many more. [analogy: consider an object of a class]
3. understand the concept of port mapping.
4. common docker commands.
    - docker run/kill
    - docker ps/exec
    - docker images
    - docker push
    - docker build [creating your own docker image.]
5. create a docker image locally.
    -build and run a container of the image.
    -push it on docker and remove it from local machine and then run it again to pull it locally.

#week 26.2
1. layers in docker.
    - caching and optimising the cached layers to optimise the build process.
    - always try to use cached layer from previous build if it's not dependent or unchanged.
2. volumes in docker.
3. networks in docker.

--------------------------------------------------------------------------------------------

#week 27.1
1. docker-compose 
2. create a monorepo, and write CI/CD pipeline to deploy it.
Task: monorepo deployment to VM via CI/CD using docker.